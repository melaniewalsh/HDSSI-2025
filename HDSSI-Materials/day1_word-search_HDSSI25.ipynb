{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for a Word in Context with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll look at code for reading in a text file and searching for a word in context within that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the modules/packages we need for the rest of our process. In this case, we just need the regular expression module. \n",
    "\n",
    "Click `Shift + Enter/Return` or `⏵ Run` to run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a file and print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll read in a text file. Specifically, let's look at a collection of poetry by UW students, which was published just over 100 years ago: *University of Washington Poems* (1924), edited by Glenn Hughes. \n",
    "\n",
    "Before you read in the file, take a look at a scan of the original edition: https://babel.hathitrust.org/cgi/pt?id=uc1.$b247983&seq=7  \n",
    "\n",
    "Then, run the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'UW-1920s-poetry.txt'\n",
    "\n",
    "txt_start=2180\n",
    "txt_end=3900\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[txt_start:txt_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it:** shift the printing window above by changing the `txt_start` and `txt_end` variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search a text file for a specific word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below we create a function that will accept:\n",
    "  - filename: name of the file to read\n",
    "- search_term: the word to search for (case-insensitive)\n",
    "- num_results: maximum number of context examples to print (default: 5)\n",
    "- context_window: number of characters to show before/after the word (default: 30)\n",
    "\n",
    "Run the cell below - do not edit it if you are trying to follow along :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_word_in_file(filename, word, num_print=5, context_window=30):\n",
    "    \n",
    "    \"\"\"\n",
    "    Search for a word in a text file and print the number of occurrences.\n",
    "    Optionally print the context for each occurrence.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename: name of the file to read\n",
    "    - word: the word to search for (case-insensitive)\n",
    "    - num_print: maximum number of context examples to print (default: 5)\n",
    "    - context: number of characters to show before/after the word (default: 30)\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the file and read the contents into a single string\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Find all matches of the word (case-insensitive, as a whole word)\n",
    "    # r'\\b' means \"word boundary\" so we only match the full word\n",
    "    matches = [m for m in re.finditer(r'\\b{}\\b'.format(re.escape(word)), text, re.IGNORECASE)]\n",
    "\n",
    "    # Print the number of times the word appears\n",
    "    print(f\"The word '{word}' appears {len(matches)} times in the text.\\n\")\n",
    "\n",
    "    # Print up to num_print occurrences with context\n",
    "    for i, match in enumerate(matches[:num_print]):\n",
    "        # Get start and end position of the match\n",
    "        start, end = match.start(), match.end()\n",
    "        # Get context before and after the word\n",
    "        before = text[max(0, start-context_window):start]\n",
    "        after = text[end:end+context_window]\n",
    "        # Print with ... to show it's a snippet\n",
    "        print(f\"✨{before}[{text[start:end]}]{after}✨\\n\\n\")\n",
    "\n",
    "    if len(matches) > num_print:\n",
    "        print(f\"\\n[Showing {num_results} out of {len(matches)} occurrences. Increase num_print to see more.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell reads in the file we've selected (`filename`), searches for a specified term (`search_term`), and returns a specified number of results (`num_results`) for appearances of that term, printed within context windows of length (`context_window`) on either side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'UW-1920s-poetry.txt'\n",
    "search_term = 'rain'\n",
    "num_results = 15\n",
    "context_window=40\n",
    "\n",
    "search_word_in_file(filename, search_term, num_results, context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it:** shift the number of results returned and/or the number of characters returned in each result by adjusting the `num_results` and `context_window` variables above. Look at how the word \"rain\" (or other terms you're interested in) appear within poems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for a term in a different text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching within a text file drawn from a printed text with a more complex layout can be more complicated. Let's go back to the issue of the *Seattle Star* we were looking at before. A scan of the issue is available here: https://chroniclingamerica.loc.gov/lccn/sn87093407/1925-06-23/ed-1/seq-1/\n",
    "\n",
    "Once you've looked at the issue, try reading in a chunk of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Seattle-Star_06231925.txt'\n",
    "\n",
    "txt_start=0\n",
    "txt_end=2000\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[txt_start:txt_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can call the same function we wrote above, `search_word_in_file`, to search this new file. \n",
    "\n",
    "Edit the variables below to try searching for a new search term within the newspaper pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Seattle-Star_06231925.txt'\n",
    "search_term = 'rain'\n",
    "num_results = 15\n",
    "context_window=80\n",
    "\n",
    "search_word_in_file(filename, search_term, num_results, context_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
